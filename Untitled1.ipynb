{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "import re\n",
    "import os\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, GRU, Embedding, Layer\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "from src.helpme import clean_text,start_end_tagger,max_length,tokenize,preprocess,preprocess_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/kor.txt', sep='\\t', names=['eng','kor','drop_me'])\n",
    "df_test = df_test.drop(columns='drop_me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop([3317,3316])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>kor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>가.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>안녕.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>뛰어!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run.</td>\n",
       "      <td>뛰어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>누구?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>Why don't we just reformat the hard disk? You'...</td>\n",
       "      <td>우리 그냥 하드 디스크를 새로 포맷하는 건 어때? 너무 그걸로 스트레스 많이 받고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>I knew that Tom was just a freshman, so I was ...</td>\n",
       "      <td>난 톰이 그냥 신입생일 뿐이라고만 알았는데, 그러다보니 톰이랑 선배들이 서로 어울려...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>Tom always cried when his sister took away his...</td>\n",
       "      <td>톰은 누나가 자기 장난감을 빼앗아 갔을 때마다 울음을 터뜨렸고, 누나는 바로 그런 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>Science fiction has undoubtedly been the inspi...</td>\n",
       "      <td>공상 과학 소설은 의심의 여지 없이 오늘날 존재하는 많은 기술에 영감을 주었어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>I started a new blog. I'll do my best not to b...</td>\n",
       "      <td>난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    eng  \\\n",
       "0                                                   Go.   \n",
       "1                                                   Hi.   \n",
       "2                                                  Run!   \n",
       "3                                                  Run.   \n",
       "4                                                  Who?   \n",
       "...                                                 ...   \n",
       "3311  Why don't we just reformat the hard disk? You'...   \n",
       "3312  I knew that Tom was just a freshman, so I was ...   \n",
       "3313  Tom always cried when his sister took away his...   \n",
       "3314  Science fiction has undoubtedly been the inspi...   \n",
       "3315  I started a new blog. I'll do my best not to b...   \n",
       "\n",
       "                                                    kor  \n",
       "0                                                    가.  \n",
       "1                                                   안녕.  \n",
       "2                                                   뛰어!  \n",
       "3                                                   뛰어.  \n",
       "4                                                   누구?  \n",
       "...                                                 ...  \n",
       "3311  우리 그냥 하드 디스크를 새로 포맷하는 건 어때? 너무 그걸로 스트레스 많이 받고 ...  \n",
       "3312  난 톰이 그냥 신입생일 뿐이라고만 알았는데, 그러다보니 톰이랑 선배들이 서로 어울려...  \n",
       "3313  톰은 누나가 자기 장난감을 빼앗아 갔을 때마다 울음을 터뜨렸고, 누나는 바로 그런 ...  \n",
       "3314       공상 과학 소설은 의심의 여지 없이 오늘날 존재하는 많은 기술에 영감을 주었어.  \n",
       "3315  난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...  \n",
       "\n",
       "[3316 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('data/final_df_fix.txt',sep='\\t')\n",
    "\n",
    "df_all = df_all.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = preprocess(df_test['eng'])\n",
    "kor = preprocess(df_test['kor'])\n",
    "\n",
    "input_tensor, input_lang_tokenizer = tokenize(eng)\n",
    "target_tensor, target_lang_tokenizer = tokenize(kor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 2338\n",
      "Korean vocab size: 5063\n",
      "Longest English Sentence: 31\n",
      "Longest Korean Sentence: 19\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(input_lang_tokenizer.word_index)+1\n",
    "kor_vocab_size = len(target_lang_tokenizer.word_index)+1\n",
    "\n",
    "print(f'English vocab size: {eng_vocab_size}')\n",
    "print(f'Korean vocab size: {kor_vocab_size}')\n",
    "\n",
    "eng_max_length = len(input_tensor[0])\n",
    "kor_max_length = len(target_tensor[0])\n",
    "\n",
    "print(f'Longest English Sentence: {eng_max_length}')\n",
    "print(f'Longest Korean Sentence: {kor_max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = preprocess(df_all['eng'])\n",
    "kor = preprocess(df_all['kor'])\n",
    "\n",
    "input_tensor, input_lang_tokenizer = tokenize(eng)\n",
    "target_tensor, target_lang_tokenizer = tokenize(kor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 12251\n",
      "Korean vocab size: 58663\n",
      "Longest English Sentence: 45\n",
      "Longest Korean Sentence: 15\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(input_lang_tokenizer.word_index)+1\n",
    "kor_vocab_size = len(target_lang_tokenizer.word_index)+1\n",
    "\n",
    "print(f'English vocab size: {eng_vocab_size}')\n",
    "print(f'Korean vocab size: {kor_vocab_size}')\n",
    "\n",
    "eng_max_length = len(input_tensor[0])\n",
    "kor_max_length = len(target_tensor[0])\n",
    "\n",
    "print(f'Longest English Sentence: {eng_max_length}')\n",
    "print(f'Longest Korean Sentence: {kor_max_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor1 = input_tensor[:1000]\n",
    "target_tensor1 = target_tensor[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,),name='Encoder_input')\n",
    "embedding_dim=50\n",
    "embedded_input = Embedding(input_dim=eng_vocab_size,\n",
    "                           output_dim=embedding_dim,\n",
    "                           name='Embedding_layer')(encoder_input)\n",
    "encoder_lstm = LSTM(units=50,\n",
    "                   activation='relu',\n",
    "                   return_sequences=False,\n",
    "                   return_state=True,\n",
    "                   name='Encoder_lstm')\n",
    "encoder_out, enc_h_state, enc_c_state = encoder_lstm(embedded_input)\n",
    "\n",
    "decoder_input = Input(shape=(None,1), name='Decoder_input')\n",
    "# embedded_decoder = Embedding(kor_vocab_size,\n",
    "#                             100,\n",
    "#                             name='Decoder_embedded_layer')(decoder_input)\n",
    "decoder_lstm = LSTM(units=50,\n",
    "                   activation='relu',\n",
    "                   return_sequences=True,\n",
    "                   return_state=True,\n",
    "                   name='Decoder_lstm')\n",
    "decoder_out,_,_ = decoder_lstm(decoder_input,initial_state=[enc_h_state,enc_c_state])\n",
    "\n",
    "final_dense = Dense(kor_vocab_size,activation='softmax',name='Final_dense_layer')\n",
    "logits = final_dense(decoder_out)\n",
    "\n",
    "model = Model([encoder_input,decoder_input],logits)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_layer (Embedding)     (None, None, 50)     612550      Encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_input (InputLayer)      [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_lstm (LSTM)             [(None, 50), (None,  20200       Embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_lstm (LSTM)             [(None, None, 50), ( 10400       Decoder_input[0][0]              \n",
      "                                                                 Encoder_lstm[0][1]               \n",
      "                                                                 Encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Final_dense_layer (Dense)       (None, None, 58663)  2991813     Decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,634,963\n",
      "Trainable params: 3,634,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 103)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_kor_input = target_tensor.reshape((-1,kor_max_length,1))[:,:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_kor_target = target_tensor.reshape((-1,kor_max_length,1))[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78528 samples, validate on 19633 samples\n",
      "Epoch 1/15\n",
      "78528/78528 [==============================] - 789s 10ms/sample - loss: 3.4745 - acc: 0.6879 - val_loss: 3.1424 - val_acc: 0.7068\n",
      "Epoch 2/15\n",
      "34580/78528 [============>.................] - ETA: 9:48 - loss: 2.8387 - acc: 0.6961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c2aac04f0371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m          validation_split=0.2)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([input_tensor,decoder_kor_input],decoder_kor_target,\n",
    "         epochs=15,\n",
    "         batch_size=20,\n",
    "         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_layer (Embedding)     (None, None, 50)     612550      Encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_input (InputLayer)      [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_lstm (LSTM)             [(None, 50), (None,  20200       Embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_lstm (LSTM)             [(None, None, 50), ( 10400       Decoder_input[0][0]              \n",
      "                                                                 Encoder_lstm[0][1]               \n",
      "                                                                 Encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Final_dense_layer (Dense)       (None, None, 58663)  2991813     Decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,634,963\n",
      "Trainable params: 3,634,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder_model = Model(encoder_input, [enc_h_state, enc_c_state])\n",
    "\n",
    "decoder_initial_states = [Input(shape=(50,)),\n",
    "                         Input(shape=(50,))]\n",
    "\n",
    "decoder_output, dec_h_state, dec_c_state = decoder_lstm(decoder_input, initial_state=decoder_initial_states)\n",
    "\n",
    "logits = final_dense(decoder_output)\n",
    "\n",
    "inf_decoder_model = Model([decoder_input] + decoder_initial_states, [logits,dec_h_state, dec_c_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_input (InputLayer)      [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_lstm (LSTM)             [(None, None, 50), ( 10400       Decoder_input[0][0]              \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Final_dense_layer (Dense)       (None, None, 58663)  2991813     Decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,002,213\n",
      "Trainable params: 3,002,213\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_lang_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8fbcf2210cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkor_id2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtarget_lang_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'target_lang_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "kor_id2word = {idx:word for word, idx in target_lang_tokenizer.word_index.items()}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<start>',\n",
       " 2: '<end>',\n",
       " 3: '내',\n",
       " 4: '난',\n",
       " 5: '날',\n",
       " 6: '널',\n",
       " 7: '더',\n",
       " 8: '수',\n",
       " 9: '그',\n",
       " 10: '내가',\n",
       " 11: '나',\n",
       " 12: '이',\n",
       " 13: '다',\n",
       " 14: '넌',\n",
       " 15: '너를',\n",
       " 16: '너',\n",
       " 17: '너의',\n",
       " 18: '또',\n",
       " 19: '나를',\n",
       " 20: '걸',\n",
       " 21: '있어',\n",
       " 22: '해',\n",
       " 23: '없어',\n",
       " 24: '왜',\n",
       " 25: 'oh',\n",
       " 26: '내게',\n",
       " 27: '니',\n",
       " 28: '니가',\n",
       " 29: '우리',\n",
       " 30: '너무',\n",
       " 31: '네',\n",
       " 32: '한',\n",
       " 33: '다시',\n",
       " 34: '네가',\n",
       " 35: '너와',\n",
       " 36: '없는',\n",
       " 37: '나는',\n",
       " 38: '나의',\n",
       " 39: '봐',\n",
       " 40: '게',\n",
       " 41: '것',\n",
       " 42: '거야',\n",
       " 43: '모든',\n",
       " 44: '좀',\n",
       " 45: '안',\n",
       " 46: '지금',\n",
       " 47: '않아',\n",
       " 48: '싶어',\n",
       " 49: '같아',\n",
       " 50: '돼',\n",
       " 51: '같은',\n",
       " 52: '건',\n",
       " 53: 'yeah',\n",
       " 54: '말',\n",
       " 55: '있는',\n",
       " 56: '이젠',\n",
       " 57: '이렇게',\n",
       " 58: '마',\n",
       " 59: '이제',\n",
       " 60: '때',\n",
       " 61: '못',\n",
       " 62: '우린',\n",
       " 63: '두',\n",
       " 64: '잘',\n",
       " 65: '밤',\n",
       " 66: '할',\n",
       " 67: '맘',\n",
       " 68: '매일',\n",
       " 69: '함께',\n",
       " 70: '속에',\n",
       " 71: '그래',\n",
       " 72: 'baby',\n",
       " 73: '없이',\n",
       " 74: '자꾸',\n",
       " 75: '너는',\n",
       " 76: '정말',\n",
       " 77: '보고',\n",
       " 78: '저',\n",
       " 79: '모두',\n",
       " 80: '눈을',\n",
       " 81: '오늘',\n",
       " 82: '그냥',\n",
       " 83: '몰라',\n",
       " 84: '다른',\n",
       " 85: '너에게',\n",
       " 86: '이런',\n",
       " 87: '순간',\n",
       " 88: '맘을',\n",
       " 89: '줘',\n",
       " 90: '나도',\n",
       " 91: '그대',\n",
       " 92: '아직',\n",
       " 93: '그런',\n",
       " 94: '톰은',\n",
       " 95: '너만',\n",
       " 96: '사람',\n",
       " 97: '시간이',\n",
       " 98: '손을',\n",
       " 99: '좋아',\n",
       " 100: '곁에',\n",
       " 101: '사랑',\n",
       " 102: '듯',\n",
       " 103: '해도',\n",
       " 104: '계속',\n",
       " 105: '참',\n",
       " 106: '꼭',\n",
       " 107: '줄',\n",
       " 108: '혼자',\n",
       " 109: '하나',\n",
       " 110: '그렇게',\n",
       " 111: '눈',\n",
       " 112: '네게',\n",
       " 113: '못해',\n",
       " 114: '시간',\n",
       " 115: '항상',\n",
       " 116: '가',\n",
       " 117: '수가',\n",
       " 118: '하고',\n",
       " 119: '이미',\n",
       " 120: '맘이',\n",
       " 121: '늘',\n",
       " 122: '너도',\n",
       " 123: '어떤',\n",
       " 124: '말고',\n",
       " 125: '볼',\n",
       " 126: '어떻게',\n",
       " 127: '사랑해',\n",
       " 128: '많이',\n",
       " 129: '점점',\n",
       " 130: '보면',\n",
       " 131: '같이',\n",
       " 132: '조금',\n",
       " 133: '눈이',\n",
       " 134: '알아',\n",
       " 135: '싶은',\n",
       " 136: '안에',\n",
       " 137: '마음',\n",
       " 138: '속',\n",
       " 139: '하는',\n",
       " 140: '와',\n",
       " 141: '보여',\n",
       " 142: '아무',\n",
       " 143: '오늘도',\n",
       " 144: '언제나',\n",
       " 145: '하지',\n",
       " 146: '제발',\n",
       " 147: '위해',\n",
       " 148: '아직도',\n",
       " 149: '좋은',\n",
       " 150: '나와',\n",
       " 151: '알고',\n",
       " 152: 'uh',\n",
       " 153: '사랑을',\n",
       " 154: '거',\n",
       " 155: '나만',\n",
       " 156: '척',\n",
       " 157: '말해',\n",
       " 158: '맘에',\n",
       " 159: '아닌',\n",
       " 160: '눈물이',\n",
       " 161: '마치',\n",
       " 162: '뭘',\n",
       " 163: '말을',\n",
       " 164: '그저',\n",
       " 165: '될',\n",
       " 166: '절대',\n",
       " 167: '있게',\n",
       " 168: 'no',\n",
       " 169: '그게',\n",
       " 170: '하루',\n",
       " 171: '누가',\n",
       " 172: '뭐',\n",
       " 173: '내겐',\n",
       " 174: '딱',\n",
       " 175: '이대로',\n",
       " 176: '오',\n",
       " 177: '손',\n",
       " 178: '싫어',\n",
       " 179: '아냐',\n",
       " 180: '여기',\n",
       " 181: '봐도',\n",
       " 182: '세상',\n",
       " 183: '작은',\n",
       " 184: '것만',\n",
       " 185: '사랑이',\n",
       " 186: '앞에',\n",
       " 187: '멀리',\n",
       " 188: '처음',\n",
       " 189: 'you',\n",
       " 190: '영원히',\n",
       " 191: '가는',\n",
       " 192: '말이',\n",
       " 193: '하지만',\n",
       " 194: '않는',\n",
       " 195: '괜찮아',\n",
       " 196: '아주',\n",
       " 197: '땐',\n",
       " 198: '모습',\n",
       " 199: '마음을',\n",
       " 200: '꿈을',\n",
       " 201: '많은',\n",
       " 202: '가득',\n",
       " 203: '원해',\n",
       " 204: '이건',\n",
       " 205: '안돼',\n",
       " 206: '길을',\n",
       " 207: '오직',\n",
       " 208: '눈물',\n",
       " 209: '있다면',\n",
       " 210: '옆에',\n",
       " 211: '바로',\n",
       " 212: 'i',\n",
       " 213: '자꾸만',\n",
       " 214: '않게',\n",
       " 215: '아름다운',\n",
       " 216: '온',\n",
       " 217: '그만',\n",
       " 218: '그대로',\n",
       " 219: '보는',\n",
       " 220: '전에',\n",
       " 221: '그댈',\n",
       " 222: '마음이',\n",
       " 223: '가슴이',\n",
       " 224: '톰이',\n",
       " 225: '사랑은',\n",
       " 226: '아무것도',\n",
       " 227: '단',\n",
       " 228: '전부',\n",
       " 229: '눈에',\n",
       " 230: '이제는',\n",
       " 231: '기억',\n",
       " 232: '둘',\n",
       " 233: '따라',\n",
       " 234: '채',\n",
       " 235: '밤이',\n",
       " 236: '몇',\n",
       " 237: '아무도',\n",
       " 238: '너란',\n",
       " 239: '이게',\n",
       " 240: '갈',\n",
       " 241: '있을까',\n",
       " 242: '알',\n",
       " 243: '느낌',\n",
       " 244: '오늘은',\n",
       " 245: '여전히',\n",
       " 246: '만큼',\n",
       " 247: '않을',\n",
       " 248: '사이',\n",
       " 249: '있잖아',\n",
       " 250: '건지',\n",
       " 251: '있을',\n",
       " 252: '우리가',\n",
       " 253: '말도',\n",
       " 254: '일',\n",
       " 255: '본',\n",
       " 256: '너로',\n",
       " 257: '향해',\n",
       " 258: '무슨',\n",
       " 259: '우릴',\n",
       " 260: '다가와',\n",
       " 261: '혹시',\n",
       " 262: '기분',\n",
       " 263: '더는',\n",
       " 264: '위로',\n",
       " 265: '그대가',\n",
       " 266: '모르게',\n",
       " 267: 'hey',\n",
       " 268: '근데',\n",
       " 269: '하늘',\n",
       " 270: '이상',\n",
       " 271: '대로',\n",
       " 272: '잡고',\n",
       " 273: '순',\n",
       " 274: '서로',\n",
       " 275: '숨이',\n",
       " 276: 'girl',\n",
       " 277: '것도',\n",
       " 278: '듯이',\n",
       " 279: '찾아',\n",
       " 280: '가슴',\n",
       " 281: '한번',\n",
       " 282: '번',\n",
       " 283: '위한',\n",
       " 284: '달콤한',\n",
       " 285: '시간을',\n",
       " 286: '맘은',\n",
       " 287: '우리의',\n",
       " 288: '심장이',\n",
       " 289: '아니야',\n",
       " 290: '아',\n",
       " 291: '마지막',\n",
       " 292: '빛이',\n",
       " 293: '들어',\n",
       " 294: '걸까',\n",
       " 295: '때문에',\n",
       " 296: '쉽게',\n",
       " 297: '줄게',\n",
       " 298: '그때',\n",
       " 299: '잊지',\n",
       " 300: '세상이',\n",
       " 301: '먼저',\n",
       " 302: '시간은',\n",
       " 303: '가끔',\n",
       " 304: '나에게',\n",
       " 305: '것처럼',\n",
       " 306: '아픈',\n",
       " 307: '않은',\n",
       " 308: 'woo',\n",
       " 309: '때까지',\n",
       " 310: '눈빛',\n",
       " 311: '꿈',\n",
       " 312: '미안해',\n",
       " 313: '못한',\n",
       " 314: '어떡해',\n",
       " 315: '바래',\n",
       " 316: '별',\n",
       " 317: '어서',\n",
       " 318: '숨',\n",
       " 319: '가까이',\n",
       " 320: '뭐가',\n",
       " 321: '아니',\n",
       " 322: '너무나',\n",
       " 323: '적',\n",
       " 324: '얼마나',\n",
       " 325: '어느새',\n",
       " 326: '예쁜',\n",
       " 327: '했어',\n",
       " 328: '만나',\n",
       " 329: '대체',\n",
       " 330: '가장',\n",
       " 331: '소리',\n",
       " 332: '버린',\n",
       " 333: '속에서',\n",
       " 334: '괜히',\n",
       " 335: '품에',\n",
       " 336: '아무리',\n",
       " 337: '둘이',\n",
       " 338: '그래도',\n",
       " 339: '기다려',\n",
       " 340: '세상에',\n",
       " 341: '했던',\n",
       " 342: '때면',\n",
       " 343: '필요',\n",
       " 344: '되어',\n",
       " 345: '사실',\n",
       " 346: '긴',\n",
       " 347: '웃고',\n",
       " 348: '생각',\n",
       " 349: '조금씩',\n",
       " 350: '길',\n",
       " 351: '그대를',\n",
       " 352: '잡아',\n",
       " 353: '보며',\n",
       " 354: '위에',\n",
       " 355: '밤을',\n",
       " 356: '자',\n",
       " 357: 'my',\n",
       " 358: '필요해',\n",
       " 359: '진짜',\n",
       " 360: '아파',\n",
       " 361: '생각해',\n",
       " 362: '노래',\n",
       " 363: '예뻐',\n",
       " 364: '원하는',\n",
       " 365: '끝까지',\n",
       " 366: '끝이',\n",
       " 367: '슬픈',\n",
       " 368: '가고',\n",
       " 369: '미소',\n",
       " 370: '뭔가',\n",
       " 371: '벌써',\n",
       " 372: '놓지',\n",
       " 373: '깊이',\n",
       " 374: '이유',\n",
       " 375: '된',\n",
       " 376: '막',\n",
       " 377: '결국',\n",
       " 378: '어때',\n",
       " 379: '없을',\n",
       " 380: '어디',\n",
       " 381: '서',\n",
       " 382: '걸어',\n",
       " 383: '되는',\n",
       " 384: '아는',\n",
       " 385: '머리',\n",
       " 386: '바람',\n",
       " 387: '닿을',\n",
       " 388: '남아',\n",
       " 389: '모르는',\n",
       " 390: '줄래',\n",
       " 391: '됐어',\n",
       " 392: '세상을',\n",
       " 393: '내게로',\n",
       " 394: '거짓말',\n",
       " 395: '몰래',\n",
       " 396: '말은',\n",
       " 397: '천천히',\n",
       " 398: '달라',\n",
       " 399: '왠지',\n",
       " 400: '빛을',\n",
       " 401: '불러',\n",
       " 402: '알잖아',\n",
       " 403: '바보',\n",
       " 404: '여자',\n",
       " 405: '아니면',\n",
       " 406: '없잖아',\n",
       " 407: '밤에',\n",
       " 408: '마요',\n",
       " 409: '않아도',\n",
       " 410: '빨리',\n",
       " 411: '있던',\n",
       " 412: '홀로',\n",
       " 413: '있으면',\n",
       " 414: '아마',\n",
       " 415: '꽉',\n",
       " 416: 'love',\n",
       " 417: '나쁜',\n",
       " 418: '따윈',\n",
       " 419: '어느',\n",
       " 420: '듣고',\n",
       " 421: '잠시',\n",
       " 422: '만들어',\n",
       " 423: '종일',\n",
       " 424: '다신',\n",
       " 425: '곳',\n",
       " 426: '만난',\n",
       " 427: '비가',\n",
       " 428: '향한',\n",
       " 429: '모습이',\n",
       " 430: '그리',\n",
       " 431: '목소리',\n",
       " 432: '기억해',\n",
       " 433: '어딜',\n",
       " 434: '숨을',\n",
       " 435: '생각이',\n",
       " 436: '싶지',\n",
       " 437: '말아',\n",
       " 438: '애써',\n",
       " 439: '사랑에',\n",
       " 440: '얘기',\n",
       " 441: '못할',\n",
       " 442: '너야',\n",
       " 443: '것을',\n",
       " 444: '그리고',\n",
       " 445: '하지마',\n",
       " 446: '어쩌면',\n",
       " 447: '흔들어',\n",
       " 448: '생각에',\n",
       " 449: '차가운',\n",
       " 450: '빛나는',\n",
       " 451: '그댄',\n",
       " 452: '어둠',\n",
       " 453: '안아',\n",
       " 454: '돌아와',\n",
       " 455: '이리',\n",
       " 456: 'babe',\n",
       " 457: '내일',\n",
       " 458: '멈출',\n",
       " 459: '많아',\n",
       " 460: '끝에',\n",
       " 461: '깊은',\n",
       " 462: '말해줘',\n",
       " 463: '텐데',\n",
       " 464: '사람이',\n",
       " 465: '안녕',\n",
       " 466: '하루가',\n",
       " 467: '가지',\n",
       " 468: '가슴에',\n",
       " 469: '빈',\n",
       " 470: '갖고',\n",
       " 471: '없게',\n",
       " 472: '그래서',\n",
       " 473: '하면',\n",
       " 474: '땜에',\n",
       " 475: '곳에',\n",
       " 476: '손에',\n",
       " 477: '없지',\n",
       " 478: '두고',\n",
       " 479: '춤을',\n",
       " 480: '큰',\n",
       " 481: '너만을',\n",
       " 482: '울고',\n",
       " 483: '뜨거운',\n",
       " 484: '누구도',\n",
       " 485: '느껴',\n",
       " 486: '그리워',\n",
       " 487: '새로운',\n",
       " 488: '솔직히',\n",
       " 489: '우리는',\n",
       " 490: '없던',\n",
       " 491: '잠이',\n",
       " 492: '싶은데',\n",
       " 493: '걱정',\n",
       " 494: '소중한',\n",
       " 495: '거니',\n",
       " 496: '믿어',\n",
       " 497: '말야',\n",
       " 498: '얼굴',\n",
       " 499: '멈춰',\n",
       " 500: '보이지',\n",
       " 501: 'ah',\n",
       " 502: '바람이',\n",
       " 503: '있는데',\n",
       " 504: '너라는',\n",
       " 505: '어쩔',\n",
       " 506: '언젠가',\n",
       " 507: '모르겠어',\n",
       " 508: '아래',\n",
       " 509: '집에',\n",
       " 510: '준',\n",
       " 511: '안고',\n",
       " 512: '수도',\n",
       " 513: '저기',\n",
       " 514: '있어도',\n",
       " 515: '때마다',\n",
       " 516: '바보처럼',\n",
       " 517: '이름',\n",
       " 518: '그땐',\n",
       " 519: '해줘',\n",
       " 520: '말아요',\n",
       " 521: '있지',\n",
       " 522: '빠져',\n",
       " 523: '그대의',\n",
       " 524: 'boy',\n",
       " 525: '바라봐',\n",
       " 526: '느낄',\n",
       " 527: '그건',\n",
       " 528: '않고',\n",
       " 529: '신경',\n",
       " 530: 'ooh',\n",
       " 531: '높이',\n",
       " 532: '살아',\n",
       " 533: '나만의',\n",
       " 534: '힘이',\n",
       " 535: '오래',\n",
       " 536: '잊을',\n",
       " 537: '남자',\n",
       " 538: '제일',\n",
       " 539: '보여줘',\n",
       " 540: '앞에서',\n",
       " 541: '하얀',\n",
       " 542: '말이야',\n",
       " 543: '같은데',\n",
       " 544: '거기',\n",
       " 545: '딴',\n",
       " 546: '쉴',\n",
       " 547: '두려워',\n",
       " 548: '남은',\n",
       " 549: '웃는',\n",
       " 550: '보이는',\n",
       " 551: '수많은',\n",
       " 552: '만날',\n",
       " 553: '테니까',\n",
       " 554: '조금만',\n",
       " 555: '때도',\n",
       " 556: '밤새',\n",
       " 557: '닮은',\n",
       " 558: '똑같은',\n",
       " 559: '아름다워',\n",
       " 560: '요즘',\n",
       " 561: '잊고',\n",
       " 562: '원래',\n",
       " 563: '믿고',\n",
       " 564: '흘러',\n",
       " 565: 'go',\n",
       " 566: '미친',\n",
       " 567: '테니',\n",
       " 568: '마음에',\n",
       " 569: '듯해',\n",
       " 570: '먼',\n",
       " 571: '입술',\n",
       " 572: '사람은',\n",
       " 573: '것이',\n",
       " 574: '날이',\n",
       " 575: '가끔은',\n",
       " 576: '첫',\n",
       " 577: '별이',\n",
       " 578: '그대는',\n",
       " 579: '아닌데',\n",
       " 580: '거라고',\n",
       " 581: '나랑',\n",
       " 582: '뻔한',\n",
       " 583: '말아줘',\n",
       " 584: '누구보다',\n",
       " 585: '아님',\n",
       " 586: '서로를',\n",
       " 587: '떠난',\n",
       " 588: '하늘에',\n",
       " 589: '떠나',\n",
       " 590: '어디서',\n",
       " 591: '못하고',\n",
       " 592: '추억',\n",
       " 593: '없는데',\n",
       " 594: '올',\n",
       " 595: '때론',\n",
       " 596: '마음은',\n",
       " 597: '지나',\n",
       " 598: '듯한',\n",
       " 599: '크게',\n",
       " 600: '주고',\n",
       " 601: '너가',\n",
       " 602: '있고',\n",
       " 603: '몰랐어',\n",
       " 604: '사랑하는',\n",
       " 605: '뿐',\n",
       " 606: '몸을',\n",
       " 607: '지난',\n",
       " 608: '떠올라',\n",
       " 609: '보지',\n",
       " 610: '달려',\n",
       " 611: '보다',\n",
       " 612: '있을게',\n",
       " 613: '뒤로',\n",
       " 614: '하늘을',\n",
       " 615: '좋아해',\n",
       " 616: '안아줘',\n",
       " 617: '아무렇지',\n",
       " 618: '어디든',\n",
       " 619: '같애',\n",
       " 620: '꿈이',\n",
       " 621: '자리에',\n",
       " 622: '빛',\n",
       " 623: 'up',\n",
       " 624: '모두가',\n",
       " 625: '모든걸',\n",
       " 626: '표정',\n",
       " 627: '텅',\n",
       " 628: '사랑이란',\n",
       " 629: '그럴',\n",
       " 630: '그대여',\n",
       " 631: '일이',\n",
       " 632: '어쩜',\n",
       " 633: '있니',\n",
       " 634: '중',\n",
       " 635: '생각나',\n",
       " 636: '말하고',\n",
       " 637: '미칠',\n",
       " 638: '멈추지',\n",
       " 639: '도대체',\n",
       " 640: '살짝',\n",
       " 641: '발',\n",
       " 642: '모른',\n",
       " 643: '기분이',\n",
       " 644: '행복해',\n",
       " 645: '눈빛이',\n",
       " 646: '맞춰',\n",
       " 647: '말하지',\n",
       " 648: '순간이',\n",
       " 649: 'ay',\n",
       " 650: '타고',\n",
       " 651: '아프게',\n",
       " 652: '되고',\n",
       " 653: '차라리',\n",
       " 654: '뭐든',\n",
       " 655: '웃게',\n",
       " 656: '사랑했던',\n",
       " 657: '혼자서',\n",
       " 658: '멋진',\n",
       " 659: '돌아',\n",
       " 660: '사는',\n",
       " 661: '바라보는',\n",
       " 662: '야',\n",
       " 663: '없인',\n",
       " 664: '절대로',\n",
       " 665: '의미',\n",
       " 666: '눈치',\n",
       " 667: '구름',\n",
       " 668: '할까',\n",
       " 669: '향기가',\n",
       " 670: '가도',\n",
       " 671: '뿐이야',\n",
       " 672: '너랑',\n",
       " 673: '기다리고',\n",
       " 674: '문을',\n",
       " 675: '향기',\n",
       " 676: '밖에',\n",
       " 677: '흐르는',\n",
       " 678: '언제',\n",
       " 679: '힘든',\n",
       " 680: '상처',\n",
       " 681: '새',\n",
       " 682: '떨리는',\n",
       " 683: '세상은',\n",
       " 684: '그대와',\n",
       " 685: '밤은',\n",
       " 686: '오늘따라',\n",
       " 687: '나야',\n",
       " 688: '않을게',\n",
       " 689: '취해',\n",
       " 690: '거리',\n",
       " 691: '버려',\n",
       " 692: '수는',\n",
       " 693: '온통',\n",
       " 694: '궁금해',\n",
       " 695: '조금은',\n",
       " 696: '가진',\n",
       " 697: '곁에서',\n",
       " 698: '다들',\n",
       " 699: '이래',\n",
       " 700: '사랑의',\n",
       " 701: '놈',\n",
       " 702: '기억이',\n",
       " 703: '모를',\n",
       " 704: '줘요',\n",
       " 705: '갈수록',\n",
       " 706: '기대',\n",
       " 707: '맘대로',\n",
       " 708: '말할',\n",
       " 709: '눈물을',\n",
       " 710: '힘들어',\n",
       " 711: '뒤에',\n",
       " 712: '타',\n",
       " 713: '모습을',\n",
       " 714: '가만히',\n",
       " 715: '둘만의',\n",
       " 716: '걸음',\n",
       " 717: '내려',\n",
       " 718: '우',\n",
       " 719: '감정',\n",
       " 720: '그걸',\n",
       " 721: '곳을',\n",
       " 722: '감고',\n",
       " 723: '눈부신',\n",
       " 724: '떠',\n",
       " 725: '거라',\n",
       " 726: '여기서',\n",
       " 727: '집',\n",
       " 728: '뭐야',\n",
       " 729: '하루를',\n",
       " 730: 'eh',\n",
       " 731: '해가',\n",
       " 732: '지쳐',\n",
       " 733: '찾고',\n",
       " 734: '잠',\n",
       " 735: '들어와',\n",
       " 736: '추억이',\n",
       " 737: '하나만',\n",
       " 738: '속을',\n",
       " 739: '말로',\n",
       " 740: '오지',\n",
       " 741: '걷고',\n",
       " 742: '만든',\n",
       " 743: '사랑한다',\n",
       " 744: '와서',\n",
       " 745: '담아',\n",
       " 746: '없지만',\n",
       " 747: 'it',\n",
       " 748: '있나요',\n",
       " 749: '없다',\n",
       " 750: 'know',\n",
       " 751: '알게',\n",
       " 752: '매번',\n",
       " 753: '붙잡고',\n",
       " 754: '불',\n",
       " 755: '반짝이는',\n",
       " 756: '해요',\n",
       " 757: '따뜻한',\n",
       " 758: '시작해',\n",
       " 759: '같아서',\n",
       " 760: '순간을',\n",
       " 761: '길이',\n",
       " 762: '건데',\n",
       " 763: '얼굴이',\n",
       " 764: '얘길',\n",
       " 765: '보낼',\n",
       " 766: '꿈만',\n",
       " 767: '웃을',\n",
       " 768: '이제야',\n",
       " 769: '시간에',\n",
       " 770: '사람들',\n",
       " 771: '잠깐',\n",
       " 772: '있어줘',\n",
       " 773: '터질',\n",
       " 774: '가득한',\n",
       " 775: '사랑할',\n",
       " 776: '오면',\n",
       " 777: '고마워',\n",
       " 778: '위',\n",
       " 779: '뛰어',\n",
       " 780: '사실은',\n",
       " 781: '변하지',\n",
       " 782: '어디로',\n",
       " 783: '감아',\n",
       " 784: '너만이',\n",
       " 785: '빠진',\n",
       " 786: '나란',\n",
       " 787: '손이',\n",
       " 788: '대신',\n",
       " 789: '싶다',\n",
       " 790: '여긴',\n",
       " 791: '날아',\n",
       " 792: '친구',\n",
       " 793: '몸이',\n",
       " 794: '바람에',\n",
       " 795: '않았어',\n",
       " 796: '지켜',\n",
       " 797: '뜨겁게',\n",
       " 798: '이상해',\n",
       " 799: '뭔데',\n",
       " 800: '노랠',\n",
       " 801: '환하게',\n",
       " 802: '누군가',\n",
       " 803: '잡아줘',\n",
       " 804: '어두운',\n",
       " 805: '돌아가',\n",
       " 806: '시선',\n",
       " 807: '채워',\n",
       " 808: '오랜',\n",
       " 809: '느껴져',\n",
       " 810: '멈춘',\n",
       " 811: '모습에',\n",
       " 812: '멀어져',\n",
       " 813: '굳이',\n",
       " 814: '마주',\n",
       " 815: '있다',\n",
       " 816: '살',\n",
       " 817: '아침',\n",
       " 818: '행복한',\n",
       " 819: '아직은',\n",
       " 820: '없었던',\n",
       " 821: '음',\n",
       " 822: '지금부터',\n",
       " 823: '채로',\n",
       " 824: '특별한',\n",
       " 825: '울지',\n",
       " 826: '서로의',\n",
       " 827: '날들',\n",
       " 828: '그날',\n",
       " 829: '어차피',\n",
       " 830: '없어도',\n",
       " 831: '오늘이',\n",
       " 832: '주는',\n",
       " 833: '해야',\n",
       " 834: '그럼',\n",
       " 835: '느낌이',\n",
       " 836: '차갑게',\n",
       " 837: '방',\n",
       " 838: '속으로',\n",
       " 839: '외로워',\n",
       " 840: '알았어',\n",
       " 841: '지친',\n",
       " 842: '위험해',\n",
       " 843: '볼까',\n",
       " 844: '있었어',\n",
       " 845: '좋겠어',\n",
       " 846: '갑자기',\n",
       " 847: '이야기',\n",
       " 848: '끝내',\n",
       " 849: '더욱',\n",
       " 850: '어둠이',\n",
       " 851: '이름을',\n",
       " 852: '정신',\n",
       " 853: '전',\n",
       " 854: '입',\n",
       " 855: '다음',\n",
       " 856: '푸른',\n",
       " 857: '좋아하는',\n",
       " 858: '잃은',\n",
       " 859: '미소가',\n",
       " 860: '보니',\n",
       " 861: '잊어',\n",
       " 862: '위를',\n",
       " 863: '너와의',\n",
       " 864: '끝없이',\n",
       " 865: '끝',\n",
       " 866: '달려가',\n",
       " 867: '비친',\n",
       " 868: '찾을',\n",
       " 869: '꽃',\n",
       " 870: '있도록',\n",
       " 871: '할게',\n",
       " 872: '있는지',\n",
       " 873: '뜨면',\n",
       " 874: '영화',\n",
       " 875: '못하는',\n",
       " 876: '오는',\n",
       " 877: '뛰는',\n",
       " 878: '거울',\n",
       " 879: '모든게',\n",
       " 880: '밝게',\n",
       " 881: '봐요',\n",
       " 882: '잡은',\n",
       " 883: '심장',\n",
       " 884: '차',\n",
       " 885: '몰라도',\n",
       " 886: '너에게로',\n",
       " 887: '노래가',\n",
       " 888: '없네',\n",
       " 889: '모르고',\n",
       " 890: '완벽한',\n",
       " 891: '울려',\n",
       " 892: '웃어',\n",
       " 893: '멍하니',\n",
       " 894: '가면',\n",
       " 895: '알면서도',\n",
       " 896: '눈앞에',\n",
       " 897: '끝을',\n",
       " 898: '멋대로',\n",
       " 899: '떠나지',\n",
       " 900: '되면',\n",
       " 901: '버릴',\n",
       " 902: '이럴',\n",
       " 903: '있지만',\n",
       " 904: '두근두근',\n",
       " 905: '어제',\n",
       " 906: '미워',\n",
       " 907: 'but',\n",
       " 908: '빛나',\n",
       " 909: '나에겐',\n",
       " 910: '순간에',\n",
       " 911: '그대만',\n",
       " 912: '약속해',\n",
       " 913: '낯선',\n",
       " 914: '안에서',\n",
       " 915: '왔어',\n",
       " 916: '했는데',\n",
       " 917: '말에',\n",
       " 918: '곳으로',\n",
       " 919: '전화',\n",
       " 920: '기억을',\n",
       " 921: '넘어',\n",
       " 922: '바다',\n",
       " 923: '밝은',\n",
       " 924: '일어나',\n",
       " 925: '곁을',\n",
       " 926: '걷는',\n",
       " 927: '하얗게',\n",
       " 928: '괜찮은',\n",
       " 929: '부르는',\n",
       " 930: '같지',\n",
       " 931: '햇살',\n",
       " 932: 'so',\n",
       " 933: '안겨',\n",
       " 934: '비춰',\n",
       " 935: '열어',\n",
       " 936: 'me',\n",
       " 937: '버리고',\n",
       " 938: '가질',\n",
       " 939: '어디에',\n",
       " 940: '같던',\n",
       " 941: '중에',\n",
       " 942: '불을',\n",
       " 943: '늦은',\n",
       " 944: '있죠',\n",
       " 945: '나서',\n",
       " 946: '속의',\n",
       " 947: '말투',\n",
       " 948: '잠든',\n",
       " 949: '못하게',\n",
       " 950: '없다고',\n",
       " 951: '미치겠어',\n",
       " 952: '겁이',\n",
       " 953: '생각을',\n",
       " 954: '후',\n",
       " 955: '사라져',\n",
       " 956: '전혀',\n",
       " 957: '이별',\n",
       " 958: '없었어',\n",
       " 959: '눈부시게',\n",
       " 960: '사랑한',\n",
       " 961: '웃음이',\n",
       " 962: '지나면',\n",
       " 963: '갈게',\n",
       " 964: '놓치지',\n",
       " 965: '들려',\n",
       " 966: '동안',\n",
       " 967: '사람들은',\n",
       " 968: '다가가',\n",
       " 969: '살고',\n",
       " 970: '목소리가',\n",
       " 971: '내일은',\n",
       " 972: '다시는',\n",
       " 973: '곧',\n",
       " 974: '미쳐',\n",
       " 975: '죽을',\n",
       " 976: '입술이',\n",
       " 977: '있어요',\n",
       " 978: '심장은',\n",
       " 979: '알지',\n",
       " 980: '적이',\n",
       " 981: '먹고',\n",
       " 982: '들',\n",
       " 983: '설레는',\n",
       " 984: '역시',\n",
       " 985: '할래',\n",
       " 986: '미치게',\n",
       " 987: '어린',\n",
       " 988: '춰',\n",
       " 989: '노래를',\n",
       " 990: '너밖에',\n",
       " 991: '싫은',\n",
       " 992: '깨워',\n",
       " 993: 'ok',\n",
       " 994: '마냥',\n",
       " 995: '없고',\n",
       " 996: '잡을',\n",
       " 997: '이별을',\n",
       " 998: '너무나도',\n",
       " 999: '감싸',\n",
       " 1000: '온종일',\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    input_sentence = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    input_sentence = pad_sequences([input_sentence],maxlen=eng_max_length,padding='post')\n",
    "    input_sentence_tensor = tf.convert_to_tensor(input_sentence)\n",
    "    return input_sentence_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = translate('tom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=25116, shape=(1, 45), dtype=int32, numpy=\n",
       "array([[  1, 109,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = inf_encoder_model.predict(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_word = np.zeros((1,1,1))\n",
    "prev_word[0,0,0] = target_lang_tokenizer.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내 내 내 내 내 내 내 내 내 내 내 내 내 내 내 내'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_condition = False\n",
    "translation = []\n",
    "\n",
    "while not stop_condition:\n",
    "    logits, h_state, c_state = inf_decoder_model.predict([prev_word] + initial_state)\n",
    "    \n",
    "    pred_id = np.argmax(logits[0,0,:])\n",
    "    pred_word = kor_id2word[pred_id]\n",
    "    translation.append(pred_word)\n",
    "    \n",
    "    if (pred_word=='<end>') or (len(translation)>kor_max_length):\n",
    "        break\n",
    "        \n",
    "    prev_word[0,0,0] = pred_id\n",
    "    initial_states=[h_state,c_state]\n",
    "    \n",
    "\" \".join(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lang_tokenizer.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
